<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>mikropml: User-Friendly R Package for Robust Machine Learning Pipelines • mikropml</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="mikropml: User-Friendly R Package for Robust Machine Learning Pipelines">
<meta property="og:description" content="mikropml">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mikropml</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="divider">
    <li class="dropdown-header">Paper</li>
    <li>
      <a href="../articles/paper.html">mikropml: User-Friendly R Package for Robust Machine Learning Pipelines</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Vignettes</li>
    <li>
      <a href="../articles/introduction.html">Introduction to mikropml</a>
    </li>
    <li>
      <a href="../articles/preprocess.html">Preprocessing data</a>
    </li>
    <li>
      <a href="../articles/parallel.html">Parallel processing</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/SchlossLab/mikropml/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><link href="paper_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet">
<script src="paper_files/anchor-sections-1.0/anchor-sections.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>mikropml: User-Friendly R Package for Robust Machine Learning Pipelines</h1>
                        <h4 class="author">Begüm D. Topçuoğlu, Zena Lapp, Kelly L. Sovacool, Evan Snitkin, Jenna Wiens, Patrick D. Schloss</h4>
            
            <h4 class="date">2020</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/SchlossLab/mikropml/blob/master/vignettes/paper.Rmd"><code>vignettes/paper.Rmd</code></a></small>
      <div class="hidden name"><code>paper.Rmd</code></div>

    </div>

    
    
<div id="summary" class="section level1">
<h1 class="hasAnchor">
<a href="#summary" class="anchor"></a>Summary</h1>
<p>Machine learning (ML) for classification and prediction based on a set of features is used to make decisions in healthcare, economics, criminal justice and more. However, implementing a robust ML pipeline can be time-consuming, confusing, and difficult. Here, we present <a href="http://www.schlosslab.org/mikropml/"><code>mikropml</code></a> (prononced “meek-ROPE em el”), an easy-to-use R package that implements robust ML pipelines using regression, support vector machines, decision trees, random forest, or gradient-boosted trees. The package is available on <a href="https://github.com/SchlossLab/mikropml/">GitHub</a> and CRAN [<strong>link to CRAN</strong>].</p>
</div>
<div id="statement-of-need" class="section level1">
<h1 class="hasAnchor">
<a href="#statement-of-need" class="anchor"></a>Statement of need</h1>
<p>A robust machine learning (ML) pipeline requires data pre-processing, cross-validation, testing, model evaluation, and often interpretation of why the model makes particular predictions. Performing these steps using the correct methodology is extremely important, as failure to implement them can result in incorrect and misleading results <span class="citation">(Teschendorff 2019; Wiens et al. 2019)</span>.</p>
<p>Supervised ML is widely used to recognize patterns in large datasets and to make predictions about outcomes of interest. Several packages including <code>caret</code> <span class="citation">(Kuhn 2008)</span> and <code>tidymodels</code> <span class="citation">(Kuhn, Wickham, and RStudio 2020)</span> in R and <code>scikitlearn</code> <span class="citation">(Pedregosa et al. 2011)</span> in Python allow scientists to train ML models with a variety of algorithms. While these packages provide all of the tools necessary for each ML step, they do not implement a complete robust ML pipeline according to best practices in the literature. This, paired with the vast number of options available, makes it difficult for non-experts to easily perform robust ML analyses using these packages. Furthermore, these packages do not offer a unified way to identify features that contribute to improved model performance.</p>
<p>To enable a broader range of researchers to perform robust ML analyses, we created <a href="https://github.com/SchlossLab/mikropml/"><code>mikropml</code></a>, an easy-to-use package in R <span class="citation">(R Core Team 2020)</span> that implements the ML framework created by Topçuoğlu <em>et al.</em> <span class="citation">(Topçuoğlu et al. 2020)</span>. <code>mikropml</code> leverages the <code>caret</code> package to support several ML algorithms: linear regression, logistic regression, support vector machine with a radial basis kernel, decision tree, random forest, and gradient boosted trees. It incorporates best practices in ML training, testing, and model evaluation <span class="citation">(Topçuoğlu et al. 2020; Teschendorff 2019)</span>. <!-- @Begum should we cite something else here [as well]? --  Added 1 more but Jenna might have opinions on this --> Furthermore, it provides data preprocessing steps based on the FIDDLE (FlexIble Data-Driven pipeLinE) framework outlined in Tang <em>et al.</em> <span class="citation">(Tang et al. 2020)</span> and post-training permutation importance steps to measure the importance of each feature in the model <span class="citation">(Breiman 2001; Fisher, Rudin, and Dominici 2018)</span>.</p>
<p>The framework implemented in <code>mikropml</code> is generalizable to perform ML on datasets from many different fields. It has already been applied to microbiome data to categorize patients with colorectal cancer <span class="citation">(Topçuoğlu et al. 2020)</span>, to identify differences in genomic and clinical features associated with bacterial infections <span class="citation">(Lapp et al. 2020)</span>, and to predict gender-based biases in academic publishing <span class="citation">(Hagan et al. 2020)</span>.</p>
</div>
<div id="mikropml-package" class="section level1">
<h1 class="hasAnchor">
<a href="#mikropml-package" class="anchor"></a>mikropml package</h1>
<p>The <code>mikropml</code> package includes functions to preprocess the data, train ML models, and quantify feature importance. We also provide <a href="http://www.schlosslab.org/mikropml/articles/index.html">vignettes</a> and an <a href="https://github.com/SchlossLab/mikropml-snakemake-workflow">example snakemake workflow</a> <span class="citation">(Köster and Rahmann 2012)</span> to showcase how to run an ideal ML pipeline with multiple different train/test data splits. The results can be visualized using helper functions that use <code>ggplot2</code> <span class="citation">(Wickham 2016)</span>.</p>
<div id="preprocessing-data" class="section level2">
<h2 class="hasAnchor">
<a href="#preprocessing-data" class="anchor"></a>Preprocessing data</h2>
<p>We provide a function <code><a href="../reference/preprocess_data.html">preprocess_data()</a></code> to preprocess features using several different functions from the <code>caret</code> package. The <code><a href="../reference/preprocess_data.html">preprocess_data()</a></code> function takes continuous and categorical data, re-factors categorical data into binary features, and provides options to normalize continuous data, remove features with near-zero variance, and keep only one instance of perfectly correlated features. We set the default options based on best practices implemented in FIDDLE <span class="citation">(Tang et al. 2020)</span>. More details on how to use <code><a href="../reference/preprocess_data.html">preprocess_data()</a></code> can be found in the accompanying <a href="http://www.schlosslab.org/mikropml/articles/preprocess.html">vignette</a>.</p>
</div>
<div id="running-ml" class="section level2">
<h2 class="hasAnchor">
<a href="#running-ml" class="anchor"></a>Running ML</h2>
<p>The main function in mikropml, <code><a href="../reference/run_ml.html">run_ml()</a></code>, minimally takes in the model choice and a data frame with an outcome column and remaining columns as categorical or continuous features. For model choice, <code>mikropml</code> currently supports logistic and linear regression <span class="citation">(Friedman, Hastie, and Tibshirani 2010)</span>, support vector machine with a radial basis kernel <span class="citation">(Karatzoglou et al. 2004)</span>, decision trees <span class="citation">(Therneau et al. 2019)</span>, random forest <span class="citation">(Liaw and Wiener 2002)</span>, and gradient-boosted trees <span class="citation">(Chen et al. 2020)</span>. <code><a href="../reference/run_ml.html">run_ml()</a></code> randomly splits the data into train and test sets while maintaining the distribution of the outcomes found in the full dataset. It also provides the option to split the data into train and test sets based on categorical variables (e.g. batch, geographic location, etc.). <code>mikropml</code> uses the <code>caret</code> package <span class="citation">(Kuhn 2008)</span> to train and evaluate the model, and optionally quantifies feature importance. The output includes the best model built based on tuning hyperparameters in an internal and repeated cross-validation step, model evaluation metrics, and optional feature importances (Figure 1). The quantification of feature importance using permutation allows the calculation of the decrease in the model’s prediction performance after breaking the relationship between the feature and the true outcome, and is thus particularly useful for model interpretation <span class="citation">(Topçuoğlu et al. 2020)</span>. Our <a href="http://www.schlosslab.org/mikropml/articles/introduction.html">vignette</a> contains a comprehensive tutorial on how to use <code><a href="../reference/run_ml.html">run_ml()</a></code>.</p>
<div class="figure">
<img src="mikRopML-pipeline.png" alt="mikropml pipeline" style="width:100.0%"><p class="caption">mikropml pipeline</p>
</div>
</div>
<div id="ideal-workflow-for-running-mikropml-with-many-different-traintest-splits" class="section level2">
<h2 class="hasAnchor">
<a href="#ideal-workflow-for-running-mikropml-with-many-different-traintest-splits" class="anchor"></a>Ideal workflow for running mikropml with many different train/test splits</h2>
<p>To investigate the variation in model performance depending on the train and test set used <span class="citation">(Topçuoğlu et al. 2020; Lapp et al. 2020)</span>, we provide examples of how to run the <code><a href="../reference/run_ml.html">run_ml()</a></code> function many times with different train/test splits and how to get summary information about model performance on <a href="http://www.schlosslab.org/mikropml/articles/parallel.html">a local computer</a> or on a high-performance computing cluster using a <a href="https://github.com/SchlossLab/mikropml-snakemake-workflow">snakemake workflow</a>.</p>
</div>
<div id="tuning-visualization" class="section level2">
<h2 class="hasAnchor">
<a href="#tuning-visualization" class="anchor"></a>Tuning &amp; visualization</h2>
<p>One particularly important aspect of ML is hyperparameter tuning. Practitioners must explore a range of hyperparameter possibilities to pick the ideal value for the model and dataset. Therefore, we provide a function <code><a href="../reference/plot_hp_performance.html">plot_hp_performance()</a></code> to plot the cross-validation performance metric of models built using different train/test splits to evaluate if we are exhausing our hyperparameter search range to pick the ideal one. We also provide summary plots of test performance metrics for the many train/test splits with different models using <code><a href="../reference/plot_model_performance.html">plot_model_performance()</a></code>.</p>
</div>
<div id="dependencies" class="section level2">
<h2 class="hasAnchor">
<a href="#dependencies" class="anchor"></a>Dependencies</h2>
<p>mikropml is written in R <span class="citation">(R Core Team 2020)</span> and depends on several packages: <code>dplyr</code> <span class="citation">(Wickham et al. 2020)</span>, <code>rlang</code> <span class="citation">(Henry, Wickham, and RStudio 2020)</span> and <code>caret</code> <span class="citation">(Kuhn 2008)</span>. The ML algorithms supported by <code>mikropml</code> require: <code>glmnet</code> <span class="citation">(Friedman, Hastie, and Tibshirani 2010)</span>, <code>e1071</code> <span class="citation">(Meyer et al. 2020)</span>, and <code>MLmetrics</code> <span class="citation">(Yan 2016)</span> for logistic regression, <code>rpart2</code> <span class="citation">(Therneau et al. 2019)</span> for decision trees, <code>randomForest</code> <span class="citation">(Liaw and Wiener 2002)</span> for random forest, <code>xgboost</code> <span class="citation">(Chen et al. 2020)</span> for xgBoost, and <code>kernlab</code> <span class="citation">(Karatzoglou et al. 2004)</span> for support vector machines. We also allow for parallelization of cross-validation and other steps using the <code>foreach</code>, <code>doFuture</code>, <code>future.apply</code>, and <code>future</code> packages <span class="citation">(Bengtsson and Team 2020)</span>. Finally, we use <code>ggplot2</code> for plotting <span class="citation">(Wickham 2016)</span>.</p>
</div>
</div>
<div id="acknowledgements" class="section level1">
<h1 class="hasAnchor">
<a href="#acknowledgements" class="anchor"></a>Acknowledgements</h1>
<p>We thank members of the Schloss Lab who participated in code clubs related to the initial development of the pipeline.</p>
</div>
<div id="funding" class="section level1">
<h1 class="hasAnchor">
<a href="#funding" class="anchor"></a>Funding</h1>
<p>Salary support for PDS came from NIH grant 1R01CA215574. KLS received support from the NIH Training Program in Bioinformatics (T32 GM070449). ZL received support from the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE 1256260. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</p>
</div>
<div id="author-contributions" class="section level1">
<h1 class="hasAnchor">
<a href="#author-contributions" class="anchor"></a>Author contributions</h1>
<p>BT, ZL, and KLS conceptualized the study and created the package. BT, ZL, JW, and PDS developed methodology. PDS, ES, and JW supervised the project. BT, ZL, and KLS wrote the original draft. All authors reviewed and edited the manuscript.</p>
</div>
<div id="conflicts-of-interest" class="section level1">
<h1 class="hasAnchor">
<a href="#conflicts-of-interest" class="anchor"></a>Conflicts of interest</h1>
<p>None.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-bengtsson_futureapply_2020">
<p>Bengtsson, Henrik, and R Core Team. 2020. “Future.Apply: Apply Function to Elements in Parallel Using Futures,” July.</p>
</div>
<div id="ref-breiman_random_2001">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1): 5–32. <a href="https://doi.org/10.1023/A:1010933404324">https://doi.org/10.1023/A:1010933404324</a>.</p>
</div>
<div id="ref-chen_xgboost_2020">
<p>Chen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2020. “Xgboost: Extreme Gradient Boosting,” June.</p>
</div>
<div id="ref-fisher2018models">
<p>Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2018. “All Models Are Wrong, but Many Are Useful: Learning a Variable’s Importance by Studying an Entire Class of Prediction Models Simultaneously.” <a href="http://arxiv.org/abs/1801.01489">http://arxiv.org/abs/1801.01489</a>.</p>
</div>
<div id="ref-friedman_regularization_2010">
<p>Friedman, Jerome H., Trevor Hastie, and Rob Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” <em>Journal of Statistical Software</em> 33 (1): 1–22. <a href="https://doi.org/10.18637/jss.v033.i01">https://doi.org/10.18637/jss.v033.i01</a>.</p>
</div>
<div id="ref-hagan_women_2020">
<p>Hagan, AK, BD Topçuoğlu, ME Gregory, HA Barton, and PD Schloss. 2020. “Women Are Underrepresented and Receive Differential Outcomes at ASM Journals: A Six-Year Retrospective Analysis.” <em>mBio</em> 11:e01680-20. <a href="https://doi.org/10.1128/mBio.01680-20">https://doi.org/10.1128/mBio.01680-20</a>.</p>
</div>
<div id="ref-henry_rlang_2020">
<p>Henry, Lionel, Hadley Wickham, and RStudio. 2020. “Rlang: Functions for Base Types and Core R and ’Tidyverse’ Features,” July.</p>
</div>
<div id="ref-karatzoglou_kernlab_2004">
<p>Karatzoglou, Alexandros, Alexandros Smola, Kurt Hornik, and Achim Zeileis. 2004. “Kernlab - an S4 Package for Kernel Methods in R.” <em>Journal of Statistical Software</em> 11 (1): 1–20. <a href="https://doi.org/10.18637/jss.v011.i09">https://doi.org/10.18637/jss.v011.i09</a>.</p>
</div>
<div id="ref-koster_snakemakescalable_2012">
<p>Köster, Johannes, and Sven Rahmann. 2012. “Snakemakea Scalable Bioinformatics Workflow Engine.” <em>Bioinformatics</em> 28 (19): 2520–2. <a href="https://doi.org/10.1093/bioinformatics/bts480">https://doi.org/10.1093/bioinformatics/bts480</a>.</p>
</div>
<div id="ref-kuhn_building_2008">
<p>Kuhn, Max. 2008. “Building Predictive Models in R Using the Caret Package.” <em>Journal of Statistical Software</em> 28 (1): 1–26. <a href="https://doi.org/10.18637/jss.v028.i05">https://doi.org/10.18637/jss.v028.i05</a>.</p>
</div>
<div id="ref-kuhn_tidymodels_2020">
<p>Kuhn, Max, Hadley Wickham, and RStudio. 2020. “Tidymodels: Easily Install and Load the ’Tidymodels’ Packages,” July.</p>
</div>
<div id="ref-lapp_machine_2020">
<p>Lapp, Zena, Jennifer Han, Jenna Wiens, Ellie JC Goldstein, Ebbing Lautenbach, and Evan Snitkin. 2020. “Machine Learning Models to Identify Patient and Microbial Genetic Factors Associated with Carbapenem-Resistant Klebsiella Pneumoniae Infection.” <em>medRxiv</em>, July, 2020.07.06.20147306. <a href="https://doi.org/10.1101/2020.07.06.20147306">https://doi.org/10.1101/2020.07.06.20147306</a>.</p>
</div>
<div id="ref-liaw_classication_2002">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest” 2: 5.</p>
</div>
<div id="ref-meyer_e1071_2020">
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, Friedrich Leisch, Chih-Chung Chang (libsvm C++-code), and Chih-Chen Lin (libsvm C++-code). 2020. “E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), TU Wien.”</p>
</div>
<div id="ref-pedregosa_scikit-learn_2011">
<p>Pedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” <em>Journal of Machine Learning Research</em> 12 (85): 2825–30.</p>
</div>
<div id="ref-r_core_team_r_2020">
<p>R Core Team. 2020. “R: A Language and Environment for Statistical Computing.”</p>
</div>
<div id="ref-tang_democratizing_2020">
<p>Tang, Shengpu, Parmida Davarmanesh, Yanmeng Song, Danai Koutra, Michael W. Sjoding, and Jenna Wiens. 2020. “Democratizing EHR Analyses with FIDDLE: A Flexible Data-Driven Preprocessing Pipeline for Structured Clinical Data.” <em>J Am Med Inform Assoc</em>, October. <a href="https://doi.org/10.1093/jamia/ocaa139">https://doi.org/10.1093/jamia/ocaa139</a>.</p>
</div>
<div id="ref-teschendorff_avoiding_2019">
<p>Teschendorff, Andrew E. 2019. “Avoiding Common Pitfalls in Machine Learning Omic Data Science.” <em>Nature Materials</em> 18 (5): 422–27. <a href="https://doi.org/10.1038/s41563-018-0241-z">https://doi.org/10.1038/s41563-018-0241-z</a>.</p>
</div>
<div id="ref-therneau_rpart_2019">
<p>Therneau, Terry, Beth Atkinson, Brian Ripley (producer of the initial R. port, and maintainer 1999-2017). 2019. “Rpart: Recursive Partitioning and Regression Trees,” April.</p>
</div>
<div id="ref-topcuoglu_framework_2020">
<p>Topçuoğlu, Begüm D., Nicholas A. Lesniak, Mack T. Ruffin, Jenna Wiens, and Patrick D. Schloss. 2020. “A Framework for Effective Application of Machine Learning to Microbiome-Based Classification Problems.” <em>mBio</em> 11 (3). <a href="https://doi.org/10.1128/mBio.00434-20">https://doi.org/10.1128/mBio.00434-20</a>.</p>
</div>
<div id="ref-wickham_ggplot2_2016">
<p>Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Use R! Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-24277-4">https://doi.org/10.1007/978-3-319-24277-4</a>.</p>
</div>
<div id="ref-wickham_dplyr_2020">
<p>Wickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and RStudio. 2020. “Dplyr: A Grammar of Data Manipulation,” August.</p>
</div>
<div id="ref-wiens_no_2019">
<p>Wiens, Jenna, Suchi Saria, Mark Sendak, Marzyeh Ghassemi, Vincent X. Liu, Finale Doshi-Velez, Kenneth Jung, et al. 2019. “Do No Harm: A Roadmap for Responsible Machine Learning for Health Care.” <em>Nat. Med.</em> 25 (9): 1337–40. <a href="https://doi.org/10.1038/s41591-019-0548-6">https://doi.org/10.1038/s41591-019-0548-6</a>.</p>
</div>
<div id="ref-yan_mlmetrics_2016">
<p>Yan, Yachen. 2016. “MLmetrics: Machine Learning Evaluation Metrics.”</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>co-first author<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>co-first author<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>co-first author<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>corresponding author<a href="#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://github.com/BTopcuoglu">Begüm Topçuoğlu</a>, <a href="https://github.com/zenalapp">Zena Lapp</a>, <a href="https://github.com/kelly-sovacool">Kelly Sovacool</a>, Evan Snitkin, Jenna Wiens, <a href="https://github.com/pschloss">Patrick Schloss</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
